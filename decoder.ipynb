{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "transformers_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "data = load_dataset(\"csv\", data_files=\"pairs_dataset.csv\", sep=\"#\")\n",
    "data = data['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_iterator(dataset, batch_size):\n",
    "    for i in range(0, len(dataset), batch_size):\n",
    "        yield dataset[i : i + batch_size][\"equation\"] + \"<sep>\" + dataset[i : i + batch_size][\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>equation</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>y\\prime= \\frac{3}{x^3+x}, \\;\\;\\;\\; y(1)=0</td>\n",
       "      <td>y = 3 \\ln x -\\frac{3}{2} \\ln {(x^2+1)} + \\frac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>y\\prime=3xy</td>\n",
       "      <td>y = C e^{\\frac{3}{2} x^2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\frac{dy}{dx}= xy^2 + 4x + 2y^2 + 8</td>\n",
       "      <td>y =2 \\tan{(x^2 +4x +2C)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\frac{dy}{dx}= e^{x+2y}, y(0)=1</td>\n",
       "      <td>y = -\\frac{1}{2} \\ln{(-2 e^x + 2+e^{-2})}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>y\\prime = x e^{2x+y}</td>\n",
       "      <td>y = - \\ln {(-\\frac{1}{2} x e^{2x} + \\frac{1}{4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    equation  \\\n",
       "0  y\\prime= \\frac{3}{x^3+x}, \\;\\;\\;\\; y(1)=0   \n",
       "1                                y\\prime=3xy   \n",
       "2        \\frac{dy}{dx}= xy^2 + 4x + 2y^2 + 8   \n",
       "3           \\frac{dy}{dx}= e^{x+2y}, y(0)=1    \n",
       "4                      y\\prime = x e^{2x+y}    \n",
       "\n",
       "                                              answer  \n",
       "0  y = 3 \\ln x -\\frac{3}{2} \\ln {(x^2+1)} + \\frac...  \n",
       "1                          y = C e^{\\frac{3}{2} x^2}  \n",
       "2                           y =2 \\tan{(x^2 +4x +2C)}  \n",
       "3          y = -\\frac{1}{2} \\ln{(-2 e^x + 2+e^{-2})}  \n",
       "4  y = - \\ln {(-\\frac{1}{2} x e^{2x} + \\frac{1}{4...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('pairs_dataset.csv', sep='#')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "special_tokens = ['<sos>', '<eos>', '<sep>', '<pad>']\n",
    "tokenizer = transformers_tokenizer.train_new_from_iterator(batch_iterator(df, 32), vocab_size=80, new_special_tokens=special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, tokenizer, data, maxlen, sep=\"<sep>\"):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.maxlen = maxlen\n",
    "        self.vocab_size = len(tokenizer.vocab)\n",
    "        self.sep = sep\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, index):\n",
    "        src = self.tokenizer(\"<sos>\" + self.data.iloc[index, 0] + self.sep)['input_ids']\n",
    "        trg = self.tokenizer(self.sep + self.data.iloc[index, 1] + \"<eos>\")['input_ids']\n",
    "        src += self.tokenizer(\"<pad>\")['input_ids'] * (self.maxlen - len(src))\n",
    "        trg += (self.tokenizer(\"<pad>\")['input_ids'] * (self.maxlen - len(trg)))\n",
    "        return torch.tensor(src[:self.maxlen]), torch.tensor(trg[:self.maxlen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "maxlen = max(df['answer'].apply(len).max(), df['equation'].apply(len).max())\n",
    "data = MyDataset(tokenizer, df, maxlen)\n",
    "train_size = int(0.8 * len(data))\n",
    "val_size = int(0.1 * len(data))\n",
    "test_size = len(data) - train_size - val_size\n",
    "train_data, val_data, test_data = random_split(data, [train_size, val_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "            self, \n",
    "            rnn_type,\n",
    "            vocab_size, \n",
    "            embedding_dim, \n",
    "            hidden_dim, \n",
    "            num_layers, \n",
    "            padding_idx,\n",
    "            dropout=0.1,\n",
    "            bidirectional=False\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.rnn_type = rnn_type\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.bidirectional = bidirectional\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=padding_idx)\n",
    "        if rnn_type == \"rnn\":\n",
    "            self.rnn = nn.RNN(\n",
    "                embedding_dim, \n",
    "                hidden_dim, \n",
    "                num_layers, \n",
    "                batch_first=True, \n",
    "                bidirectional=self.bidirectional\n",
    "            )\n",
    "        elif rnn_type == \"gru\":\n",
    "            self.rnn = nn.GRU(\n",
    "                embedding_dim, \n",
    "                hidden_dim, \n",
    "                num_layers, \n",
    "                batch_first=True, \n",
    "                bidirectional=self.bidirectional\n",
    "            )\n",
    "        else:\n",
    "            self.rnn = nn.LSTM(\n",
    "                embedding_dim,\n",
    "                hidden_dim,\n",
    "                num_layers,\n",
    "                batch_first=True,\n",
    "                dropout=dropout,\n",
    "                bidirectional=bidirectional\n",
    "            )\n",
    "        self.fc = nn.Linear(hidden_dim + self.bidirectional * hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden, cell=None):\n",
    "        x = self.embedding(x)\n",
    "        if self.rnn_type == 'lstm':\n",
    "            output, (hidden, cell) = self.rnn(x, (hidden, cell))\n",
    "            prediction = self.fc(output.squeeze(0))\n",
    "            return prediction, hidden, cell\n",
    "        else:\n",
    "            output, hidden = self.rnn(x, hidden)\n",
    "            output = self.fc(output)\n",
    "            return output, hidden\n",
    "\n",
    "    def init_hidden_cell(self, batch_size):\n",
    "        if self.rnn_type == 'lstm':\n",
    "            return (torch.zeros(self.num_layers * (1 + self.bidirectional), batch_size, self.hidden_dim),\n",
    "                    torch.zeros(self.num_layers * (1 + self.bidirectional), batch_size, self.hidden_dim))\n",
    "        else:\n",
    "            return torch.zeros(self.num_layers * (1 + self.bidirectional) , batch_size, self.hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "padding_idx = tokenizer(\"<pad>\")['input_ids'][0]\n",
    "vocab_size = tokenizer.vocab_size\n",
    "embedding_dim = 64\n",
    "hidden_dim = 128\n",
    "num_layers = 4\n",
    "learning_rate = 0.005\n",
    "model = Decoder(\"lstm\", vocab_size, embedding_dim, hidden_dim, num_layers, padding_idx, 0.1, True)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer(\"<pad>\")['input_ids'][0])\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train(model, criterion, train_loader, val_loader, optimizer, num_epochs = 1, show=False):\n",
    "    train_history = []\n",
    "    val_history = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        val_loss = 0\n",
    "        for questions, answers in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            if model.rnn_type == \"lstm\":\n",
    "                hidden, cell = model.init_hidden_cell(len(questions))\n",
    "                outputs, _, _ = model(questions, hidden, cell)\n",
    "            else:         \n",
    "                hidden = model.init_hidden_cell(len(questions))\n",
    "                outputs, _ = model(questions, hidden)\n",
    "            loss = criterion(outputs.transpose(1, 2), answers) \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_history.append(train_loss / len(train_loader))\n",
    "        \n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for questions, answers in val_loader:  \n",
    "                if model.rnn_type == \"lstm\":\n",
    "                    hidden, cell = model.init_hidden_cell(len(questions))\n",
    "                    outputs, _, _ = model(questions, hidden, cell)\n",
    "                else:\n",
    "                    hidden = model.init_hidden_cell(len(questions))\n",
    "                    outputs, hidden = model(questions, hidden)\n",
    "                loss = criterion(outputs.transpose(1, 2), answers) \n",
    "                # if loss.item() < model.best_loss:\n",
    "                #     model.best_loss = loss.item()\n",
    "                #     torch.save(model.state_dict(), f'best_{model.rnn_type}.pt')\n",
    "                val_loss += loss.item()\n",
    "        val_history.append(val_loss / len(val_loader)) \n",
    "        clear_output(True)\n",
    "        if show:\n",
    "            plt.plot(val_history, label=\"test\")\n",
    "            plt.plot(train_history, label=\"train\")\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            print(f'Epoch {epoch + 1}, Train loss: {train_history[-1]}, Val loss: {val_history[-1]}')\n",
    "        return train_history[-1], val_history[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "def translate(model, sentence, tokenizer, max_length=50):\n",
    "    model.eval()\n",
    "    answer = tokenizer.encode(\"<sos>\")\n",
    "    for token in tokenizer.encode(sentence):\n",
    "        answer.append(token)\n",
    "    answer = torch.tensor([answer], dtype=torch.int64)\n",
    "    if model.rnn_type == \"lstm\":\n",
    "        hidden, cell = model.init_hidden_cell(batch_size=1)\n",
    "        hidden = hidden.squeeze()\n",
    "        cell = cell.squeeze()\n",
    "    else:\n",
    "        hidden = model.init_hidden_cell(batch_size=1).squeeze()\n",
    "    for i in range(len(answer) - 1):\n",
    "        if model.rnn_type == \"lstm\":\n",
    "            _, hidden, cell = model(answer[:, i], hidden, cell)\n",
    "        else:\n",
    "            _, hidden = model(answer[:, i], hidden)\n",
    "    for _ in range(max_length - len(sentence)):\n",
    "        if model.rnn_type == \"lstm\":\n",
    "            logits_next, hidden, cell = model(answer[:, -1], hidden, cell)\n",
    "            p_next = F.softmax(logits_next, dim=0).data.numpy()\n",
    "        else:\n",
    "            logits_next, hidden = model(answer[:, -1], hidden)\n",
    "            p_next = F.softmax(logits_next, dim=-1).data.numpy()[0]\n",
    "        next_ix = np.random.choice(len(p_next), p=p_next)\n",
    "        if next_ix == tokenizer('<eos>')['input_ids'][0]:\n",
    "            break\n",
    "        next_ix = torch.tensor([[next_ix]], dtype=torch.int64)\n",
    "        answer = torch.cat([answer, next_ix], dim=1)\n",
    "\n",
    "    return \"\".join([tokenizer.decode(list(answer.cpu().data.numpy())[0])[len(sentence):]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_eqs = [\n",
    "    \"2xy\\mathrm{d}x + (x^2 - y^2)\\mathrm{d}y = 0\",  # в полных дифференциалах\n",
    "    \"\\frac{3x^2 + y^2}{y^2}\\mathrm{d}x - \\frac{2x^3 + 5y}{y^3}\\mathrm{d}y\",  # в полных дифференциалах\n",
    "    \"y^{\\prime}=\\mathrm{tg}{\\frac{y}{x}}+{\\frac{y}{x}}\",  # однородное\n",
    "    \"y^{\\prime}=\\cos^{2}{\\frac{y}{x}}+{\\frac{y}{x}}\",  # однородное\n",
    "    \"y^{\\prime}-y={\\frac{e^{x}}{x^{2}}}\",  # линейное 1-го порядка\n",
    "    \"(2x+y^{2})y^{\\prime}=y\",  # линейное 1-го порядка\n",
    "    \"y y^{\\prime3}+x=1\",  # не разрешенное относительно производной\n",
    "    \"y^{\\prime^{3}}+y^{2}=y y^{\\prime}(y^{\\prime}+1)\",  # не разрешенное относительно производной\n",
    "    \"2y^{\\prime}-\\frac{y}{x}=\\frac{4x^{2}}{y}\",  # уравнение Бернулли\n",
    "    \"xy^{\\prime}-2y={\\frac{x}{y}}\",  # уравнение Бернулли\n",
    "    \"2y^{\\prime\\prime}+3y^{\\prime}-5y=10\",  # неоднородные линейные\n",
    "    \"y^{\\prime\\prime}-2y^{\\prime}-8y=x^{2}+3\",  # неоднородные линейные\n",
    "    \"{\\frac{x\\,d x+y\\,d y}{y\\,\\overline{{{1+x^{2}+y^{2}}}}}}+{\\frac{y\\,d x-x\\,d y}{x^{2}+y^{2}}}=0\",  # интегрирующий множитель\n",
    "    \"(x^{2}y^{2}-1)\\,d y+2x y^{3}\\,d x=0\",  # интегрирующий множитель\n",
    "]\n",
    "valid_eqs_answers = [\n",
    "    \"3x^2 - y^3 = C\",\n",
    "    \"x + \\frac{x^3}{y^2} + \\frac{5}{y} = C\",\n",
    "    \"y=x\\arcsin(C x)\",\n",
    "    \"y(x)=x\\tan^{-1}(c_{1}+\\log(x))\",\n",
    "    \"y(x)=c_{1}\\,e^{x}-{\\frac{e^{x}}{x}}\",\n",
    "    \"x=y^{2}(\\ln y + C)\",\n",
    "    \"(x-1)^{4/3}+y^{4/3}=C\",\n",
    "    \"4y=(x+C)^{2}\",\n",
    "    \"y(x)=-{\\sqrt{x}}\\;{\\sqrt{c_{1}+2x^{2}}}\",\n",
    "    \"y(x)={\\frac{\\sqrt{x}\\;{\\sqrt{c_{1}\\,x^{3}-2}}}{\\sqrt{3}}}\",\n",
    "    \"y(x)=c_{1}\\;e^{-(5x)/2}+c_{2}\\;e^{x}-2\",\n",
    "    \"y(x)=c_{1}\\;e^{-2x}+c_{2}\\;e^{4x}-{\\frac{x^{2}}{8}}+{\\frac{x}{16}}-{\\frac{27}{64}}\",\n",
    "    \"{\\sqrt{{1+x^{2}+y^{2}}}}+\\arctan{\\frac{x}{y}}=C\",\n",
    "    \"x^{2}y+{\\frac{1}{y}}=C\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 16:38:09.685822: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-29 16:38:09.690160: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-29 16:38:09.754496: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-29 16:38:11.095143: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/yvovaa/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/yvovaa/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "\n",
    "val_references = [\n",
    "    tokenizer.decode(val_data[i][1].tolist())\n",
    "    for i in range(len(val_data))\n",
    "]\n",
    "test_references = [\n",
    "    tokenizer.decode(test_data[i][1].tolist())\n",
    "    for i in range(len(test_data))\n",
    "]\n",
    "\n",
    "def bleu_score(preds, refs):\n",
    "    return bleu.compute(predictions=preds, references=refs)[\"bleu\"]\n",
    "\n",
    "\n",
    "def accuracy(preds, refs):\n",
    "    equal_count = 0\n",
    "    for i in range(len(refs)):\n",
    "        if preds[i] == refs[i]:\n",
    "            equal_count += 1\n",
    "    return equal_count / len(refs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def predict_valid_eqs(model, file_name):\n",
    "    preds = []\n",
    "    for eq in valid_eqs:\n",
    "        preds.append(translate(model, eq, tokenizer))\n",
    "    d = dict(zip(valid_eqs_answers, preds))\n",
    "    with open(f\"valid_eqs_preds/{file_name}.pickle\", \"wb\") as handle:\n",
    "        pickle.dump(d, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   3.303 | Train PPL:  27.204\n",
      "\tValid Loss:   3.281 | Valid PPL:  26.599\n",
      "\tValid BLEU:   0.000 | Valid Accuracy:   0.000\n",
      "EPOCH 5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 50\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEPOCH \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m unique_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrnn_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_optim-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptimizer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m__emdeding-dim-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00membedding_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_bidir-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(bidirectional)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_hiddim-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhidden_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_layers-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_layers\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_lr-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_epoch-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 50\u001b[0m train_loss, valid_loss \u001b[38;5;241m=\u001b[39m train(\n\u001b[1;32m     51\u001b[0m     model,\n\u001b[1;32m     52\u001b[0m     criterion,\n\u001b[1;32m     53\u001b[0m     train_loader,\n\u001b[1;32m     54\u001b[0m     val_loader,\n\u001b[1;32m     55\u001b[0m     optimizer\n\u001b[1;32m     56\u001b[0m )\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid_loss \u001b[38;5;241m<\u001b[39m best_valid_loss:\n\u001b[1;32m     58\u001b[0m     best_valid_loss \u001b[38;5;241m=\u001b[39m valid_loss\n",
      "Cell \u001b[0;32mIn[11], line 21\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, criterion, train_loader, val_loader, optimizer, num_epochs, show)\u001b[0m\n\u001b[1;32m     19\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m), answers) \n\u001b[1;32m     20\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 21\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     22\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     23\u001b[0m train_history\u001b[38;5;241m.\u001b[39mappend(train_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/optim/optimizer.py:391\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    388\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m             )\n\u001b[0;32m--> 391\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    394\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/optim/adam.py:165\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    154\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    156\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    157\u001b[0m         group,\n\u001b[1;32m    158\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    162\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    163\u001b[0m         state_steps)\n\u001b[0;32m--> 165\u001b[0m     adam(\n\u001b[1;32m    166\u001b[0m         params_with_grad,\n\u001b[1;32m    167\u001b[0m         grads,\n\u001b[1;32m    168\u001b[0m         exp_avgs,\n\u001b[1;32m    169\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    170\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    171\u001b[0m         state_steps,\n\u001b[1;32m    172\u001b[0m         amsgrad\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamsgrad\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    173\u001b[0m         has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[1;32m    174\u001b[0m         beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[1;32m    175\u001b[0m         beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[1;32m    176\u001b[0m         lr\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    177\u001b[0m         weight_decay\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    178\u001b[0m         eps\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    179\u001b[0m         maximize\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    180\u001b[0m         foreach\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforeach\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    181\u001b[0m         capturable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcapturable\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    182\u001b[0m         differentiable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    183\u001b[0m         fused\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfused\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    184\u001b[0m         grad_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad_scale\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    185\u001b[0m         found_inf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    186\u001b[0m     )\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/optim/adam.py:315\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    313\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 315\u001b[0m func(params,\n\u001b[1;32m    316\u001b[0m      grads,\n\u001b[1;32m    317\u001b[0m      exp_avgs,\n\u001b[1;32m    318\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    319\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    320\u001b[0m      state_steps,\n\u001b[1;32m    321\u001b[0m      amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[1;32m    322\u001b[0m      has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[1;32m    323\u001b[0m      beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[1;32m    324\u001b[0m      beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[1;32m    325\u001b[0m      lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[1;32m    326\u001b[0m      weight_decay\u001b[38;5;241m=\u001b[39mweight_decay,\n\u001b[1;32m    327\u001b[0m      eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m    328\u001b[0m      maximize\u001b[38;5;241m=\u001b[39mmaximize,\n\u001b[1;32m    329\u001b[0m      capturable\u001b[38;5;241m=\u001b[39mcapturable,\n\u001b[1;32m    330\u001b[0m      differentiable\u001b[38;5;241m=\u001b[39mdifferentiable,\n\u001b[1;32m    331\u001b[0m      grad_scale\u001b[38;5;241m=\u001b[39mgrad_scale,\n\u001b[1;32m    332\u001b[0m      found_inf\u001b[38;5;241m=\u001b[39mfound_inf)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/optim/adam.py:438\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    436\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 438\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (exp_avg_sq\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    440\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[1;32m    442\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result = {\n",
    "    \"rnn_type\": [],\n",
    "    \"optimizer\": [],\n",
    "    \"bidirectional\": [],\n",
    "    \"hidden_dim\": [],\n",
    "    \"n_layers\": [],\n",
    "    \"learning_rate\": [],\n",
    "    \"embedding_dim\": [],\n",
    "    \"epoch\": [],\n",
    "    \"val_bleu\": [],\n",
    "    \"val_accuracy\": [],\n",
    "    \"test_bleu\": [],\n",
    "    \"test_accuracy\": [],\n",
    "}\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "rnn_type_options = [\"rnn\", \"gru\", \"lstm\"]\n",
    "optimizer_options = [\"Adam\", \"AdamW\"]\n",
    "#teacher_forcing_ratio_options = [0.1, 0.3, 0.5, 0.7]\n",
    "embedding_dim_options = [16, 32, 84, 128]\n",
    "lr_options = [0.0001, 0.001, 0.01, 0.1]\n",
    "n_layers_options = [2, 4, 6, 8]\n",
    "hidden_dim_options = [256, 512, 1024]\n",
    "pad_index = tokenizer(\"<pad>\")['input_ids'][0]\n",
    "for rnn_type in rnn_type_options:\n",
    "    for embedding_dim in embedding_dim_options:\n",
    "        for optimizer_name in optimizer_options:\n",
    "            for bidirectional in [False, True]:\n",
    "                for hidden_dim in hidden_dim_options:\n",
    "                    for n_layers in n_layers_options:\n",
    "                        for lr in lr_options:\n",
    "                            model = Decoder(\n",
    "                                rnn_type, \n",
    "                                vocab_size, \n",
    "                                embedding_dim, \n",
    "                                hidden_dim, \n",
    "                                n_layers, \n",
    "                                pad_index, \n",
    "                                bidirectional=bidirectional\n",
    "                            )\n",
    "                            if optimizer_name == \"Adam\":\n",
    "                                optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "                            else:\n",
    "                                optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "                            criterion = nn.CrossEntropyLoss(ignore_index=pad_index)\n",
    "                            n_epochs = 6\n",
    "                            best_valid_loss = float(\"inf\")\n",
    "                            for epoch in range(n_epochs):\n",
    "                                print(f\"EPOCH {epoch+1}\")\n",
    "                                unique_name = f\"type-{rnn_type}_optim-{optimizer_name}__emdeding-dim-{embedding_dim}_bidir-{int(bidirectional)}_hiddim-{hidden_dim}_layers-{n_layers}_lr-{lr}_epoch-{epoch+1}\"\n",
    "                                train_loss, valid_loss = train(\n",
    "                                    model,\n",
    "                                    criterion,\n",
    "                                    train_loader,\n",
    "                                    val_loader,\n",
    "                                    optimizer\n",
    "                                )\n",
    "                                if valid_loss < best_valid_loss:\n",
    "                                    best_valid_loss = valid_loss\n",
    "                                    torch.save(\n",
    "                                        model.state_dict(),\n",
    "                                        f\"rnn_models/model_{unique_name}.pt\",\n",
    "                                    )\n",
    "                                print(\n",
    "                                    f\"\\tTrain Loss: {train_loss:7.3f} | Train PPL: {np.exp(train_loss):7.3f}\"\n",
    "                                )\n",
    "                                print(\n",
    "                                    f\"\\tValid Loss: {valid_loss:7.3f} | Valid PPL: {np.exp(valid_loss):7.3f}\"\n",
    "                                )\n",
    "\n",
    "                                # compute metrics\n",
    "                                val_predictions = [\n",
    "                                    translate(\n",
    "                                        model,\n",
    "                                        tokenizer.decode(val_data[i][0]),\n",
    "                                        tokenizer,\n",
    "                                        len(val_data[i][1])\n",
    "                                    )\n",
    "                                    for i in range(len(val_data))\n",
    "                                ]\n",
    "                                test_predictions = [\n",
    "                                    translate(\n",
    "                                        model,\n",
    "                                        tokenizer.decode(test_data[i][0]),\n",
    "                                        tokenizer,\n",
    "                                        len(test_data[i][1])\n",
    "                                    )\n",
    "                                    for i in range(len(test_data))\n",
    "                                ]\n",
    "                                val_bleu = bleu_score(\n",
    "                                    preds=val_predictions, refs=val_references\n",
    "                                )\n",
    "                                test_bleu = bleu_score(\n",
    "                                    preds=test_predictions, refs=test_references\n",
    "                                )\n",
    "                                val_accuracy = accuracy(\n",
    "                                    preds=val_predictions, refs=val_references\n",
    "                                )\n",
    "                                test_accuracy = accuracy(\n",
    "                                    preds=test_predictions, refs=test_references\n",
    "                                )\n",
    "\n",
    "                                predict_valid_eqs(model, f\"pred_{unique_name}\")\n",
    "\n",
    "                                print(\n",
    "                                    f\"\\tValid BLEU: {val_bleu:7.3f} | Valid Accuracy: {val_accuracy:7.3f}\"\n",
    "                                )\n",
    "                                result[\"rnn_type\"].append(rnn_type)\n",
    "                                result[\"embedding_dim\"].append(embedding_dim)\n",
    "                                result[\"optimizer\"].append(optimizer_name)\n",
    "                                result[\"bidirectional\"].append(bidirectional)\n",
    "                                result[\"n_layers\"].append(n_layers)\n",
    "                                result[\"hidden_dim\"].append(hidden_dim)\n",
    "                                result[\"learning_rate\"].append(lr)\n",
    "                                result[\"epoch\"].append(epoch + 1)\n",
    "                                result[\"val_bleu\"].append(round(val_bleu, 3))\n",
    "                                result[\"test_bleu\"].append(round(test_bleu, 3))\n",
    "                                result[\"val_accuracy\"].append(round(val_accuracy, 3))\n",
    "                                result[\"test_accuracy\"].append(round(test_accuracy, 3))\n",
    "                                res_df = pd.DataFrame(result)\n",
    "                                res_df.to_csv(\"results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
