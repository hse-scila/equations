{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "import datasets\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"pairs_dataset.csv\")\n",
    "df2 = pd.read_csv(\"generated_pairs.csv\")\n",
    "df = pd.concat([df1, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>equation</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>y\\prime= \\frac{3}{x^3+x}, \\;\\;\\;\\; y(1)=0</td>\n",
       "      <td>y = 3 \\ln x -\\frac{3}{2} \\ln {(x^2+1)} + \\frac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>y\\prime=3xy</td>\n",
       "      <td>y = C e^{\\frac{3}{2} x^2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\frac{dy}{dx}= xy^2 + 4x + 2y^2 + 8</td>\n",
       "      <td>y =2 \\tan{(x^2 +4x +2C)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\frac{dy}{dx}= e^{x+2y}, y(0)=1</td>\n",
       "      <td>y = -\\frac{1}{2} \\ln{(-2 e^x + 2+e^{-2})}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>y\\prime = x e^{2x+y}</td>\n",
       "      <td>y = - \\ln {(-\\frac{1}{2} x e^{2x} + \\frac{1}{4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9530</th>\n",
       "      <td>y^{\\prime\\prime\\prime}-23y^{\\prime\\prime}+166y...</td>\n",
       "      <td>C_{1}e^{10x}+C_{2}e^{9x}+C_{3}e^{4x}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9531</th>\n",
       "      <td>y^{\\prime\\prime\\prime}-24y^{\\prime\\prime}+185y...</td>\n",
       "      <td>C_{1}e^{10x}+C_{2}e^{9x}+C_{3}e^{5x}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9532</th>\n",
       "      <td>y^{\\prime\\prime\\prime}-25y^{\\prime\\prime}+204y...</td>\n",
       "      <td>C_{1}e^{10x}+C_{2}e^{9x}+C_{3}e^{6x}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9533</th>\n",
       "      <td>y^{\\prime\\prime\\prime}-26y^{\\prime\\prime}+223y...</td>\n",
       "      <td>C_{1}e^{10x}+C_{2}e^{9x}+C_{3}e^{7x}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9534</th>\n",
       "      <td>y^{\\prime\\prime\\prime}-27y^{\\prime\\prime}+242y...</td>\n",
       "      <td>C_{1}e^{10x}+C_{2}e^{9x}+C_{3}e^{8x}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10670 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               equation  \\\n",
       "0             y\\prime= \\frac{3}{x^3+x}, \\;\\;\\;\\; y(1)=0   \n",
       "1                                           y\\prime=3xy   \n",
       "2                   \\frac{dy}{dx}= xy^2 + 4x + 2y^2 + 8   \n",
       "3                      \\frac{dy}{dx}= e^{x+2y}, y(0)=1    \n",
       "4                                 y\\prime = x e^{2x+y}    \n",
       "...                                                 ...   \n",
       "9530  y^{\\prime\\prime\\prime}-23y^{\\prime\\prime}+166y...   \n",
       "9531  y^{\\prime\\prime\\prime}-24y^{\\prime\\prime}+185y...   \n",
       "9532  y^{\\prime\\prime\\prime}-25y^{\\prime\\prime}+204y...   \n",
       "9533  y^{\\prime\\prime\\prime}-26y^{\\prime\\prime}+223y...   \n",
       "9534  y^{\\prime\\prime\\prime}-27y^{\\prime\\prime}+242y...   \n",
       "\n",
       "                                                 answer  \n",
       "0     y = 3 \\ln x -\\frac{3}{2} \\ln {(x^2+1)} + \\frac...  \n",
       "1                             y = C e^{\\frac{3}{2} x^2}  \n",
       "2                              y =2 \\tan{(x^2 +4x +2C)}  \n",
       "3             y = -\\frac{1}{2} \\ln{(-2 e^x + 2+e^{-2})}  \n",
       "4     y = - \\ln {(-\\frac{1}{2} x e^{2x} + \\frac{1}{4...  \n",
       "...                                                 ...  \n",
       "9530               C_{1}e^{10x}+C_{2}e^{9x}+C_{3}e^{4x}  \n",
       "9531               C_{1}e^{10x}+C_{2}e^{9x}+C_{3}e^{5x}  \n",
       "9532               C_{1}e^{10x}+C_{2}e^{9x}+C_{3}e^{6x}  \n",
       "9533               C_{1}e^{10x}+C_{2}e^{9x}+C_{3}e^{7x}  \n",
       "9534               C_{1}e^{10x}+C_{2}e^{9x}+C_{3}e^{8x}  \n",
       "\n",
       "[10670 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### characterwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "max_len = 265  # precomputed\n",
    "special_tokens = {\"<pad>\": 0, \"<sos>\": 1, \"<eos>\": 2}\n",
    "max_token = 2\n",
    "vocab = copy.copy(special_tokens)\n",
    "inverse_vocab = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def char_tokenize(sentence, is_eq, max_token, vocab):\n",
    "    tokens = []\n",
    "    if not is_eq:\n",
    "        tokens.append(special_tokens[\"<sos>\"])\n",
    "    for symbol in sentence:\n",
    "        if symbol not in vocab.keys():\n",
    "            max_token += 1\n",
    "            vocab[symbol] = max_token\n",
    "        tokens.append(vocab[symbol])\n",
    "    while len(tokens) < max_len:\n",
    "        tokens.append(special_tokens[\"<pad>\"])\n",
    "    return np.array(tokens)\n",
    "\n",
    "\n",
    "def char_detokenize(tokens: np.array, inverse_vocab, special_tokens):\n",
    "    sentence = \"\"\n",
    "    for token in tokens:\n",
    "        if token in special_tokens.values():\n",
    "            if token == special_tokens[\"<pad>\"]:\n",
    "                break\n",
    "            continue\n",
    "        sentence += inverse_vocab[token]\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def char_tokenize_lines(lines, is_eq, max_token, vocab):\n",
    "    tokenized = np.array(\n",
    "        [char_tokenize(line, is_eq, max_token, vocab) for line in lines]\n",
    "    )\n",
    "    return tokenized\n",
    "\n",
    "\n",
    "def char_tokenize_all(eq_lines, ans_lines, max_token, vocab):\n",
    "    eqs_tokenized = char_tokenize_lines(eq_lines, False, max_token, vocab)\n",
    "    ans_tokenized = char_tokenize_lines(ans_lines, True, max_token, vocab)\n",
    "    vocab = np.union1d(eqs_tokenized.flatten(), ans_tokenized.flatten())\n",
    "    vocab_size = len(vocab)\n",
    "    print(f\"Characterwise tokenization completed, vocab_size = {vocab_size}\")\n",
    "    return eqs_tokenized, ans_tokenized, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characterwise tokenization completed, vocab_size = 26\n"
     ]
    }
   ],
   "source": [
    "eqs_tokenized, ans_tokenized, vocab_size = char_tokenize_all(\n",
    "    df[\"equation\"], df[\"answer\"], max_token, vocab\n",
    ")\n",
    "\n",
    "inverse_vocab = list(vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10670, 265), (10670, 265))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eqs_tokenized.shape, ans_tokenized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pad_index = special_tokens[\"<pad>\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### minbpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(1, \"minbpe-master\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lines = \"<sos>\" + df[\"equation\"] + \" \" + df[\"answer\"] + \"<eos>\"\n",
    "str_for_vocab_training = lines.str.cat(sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from minbpe import BasicTokenizer\n",
    "\n",
    "vocab_size = 4096\n",
    "\n",
    "tokenizer = BasicTokenizer()\n",
    "# doesn't allow adding special tokens; make it learn <pad>\n",
    "str_for_vocab_training += \"<pad>\" * 10\n",
    "tokenizer.train(str_for_vocab_training, vocab_size=vocab_size)\n",
    "\n",
    "# eq_lines = \"<sos>\" + df[\"equation\"] + \"<eos>\"\n",
    "eq_lines = df[\"equation\"]\n",
    "ans_lines = \"<sos>\" + df[\"answer\"] + \"<eos>\"\n",
    "eqs_tokenized = np.array(eq_lines.apply(lambda line: list(tokenizer.encode(line))))\n",
    "ans_tokenized = np.array(ans_lines.apply(lambda line: list(tokenizer.encode(line))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seq_length = max(\n",
    "    len(max(eqs_tokenized, key=len)), len(max(ans_tokenized, key=len))\n",
    ")  # max seq len\n",
    "\n",
    "\n",
    "def pad(lines_tokenized_basic):\n",
    "    for i in range(len(lines_tokenized_basic)):\n",
    "        while len(lines_tokenized_basic[i]) < seq_length:\n",
    "            lines_tokenized_basic[i].append(tokenizer.encode(\"<pad>\")[0])\n",
    "        lines_tokenized_basic[i] = np.array(lines_tokenized_basic[i])\n",
    "    lines_tokenized_basic = np.array(lines_tokenized_basic)\n",
    "    return lines_tokenized_basic\n",
    "\n",
    "\n",
    "eqs_tokenized = pad(eqs_tokenized)\n",
    "ans_tokenized = pad(ans_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pad_index = tokenizer.encode(\"<pad>\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([ 649,  475, 1766, 2792,   43,  282, 1635, 2793,  364, 2794,  283,\n",
       "              2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711,\n",
       "              2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711,\n",
       "              2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711,\n",
       "              2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711,\n",
       "              2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711,\n",
       "              2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711])           ,\n",
       "       array([ 649,   61, 3360, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711,\n",
       "              2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711,\n",
       "              2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711,\n",
       "              2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711,\n",
       "              2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711,\n",
       "              2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711,\n",
       "              2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711])           ,\n",
       "       array([3361, 1636,  330, 1144, 2797,  943,  752, 2798,   56, 2711, 2711,\n",
       "              2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711,\n",
       "              2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711,\n",
       "              2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711,\n",
       "              2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711,\n",
       "              2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711,\n",
       "              2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711])           ,\n",
       "       ...,\n",
       "       array([ 679,  663, 1393, 1384,   52,   48,  480, 2711, 2711, 2711, 2711,\n",
       "              2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711,\n",
       "              2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711,\n",
       "              2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711,\n",
       "              2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711,\n",
       "              2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711,\n",
       "              2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711])           ,\n",
       "       array([ 679,  663, 2233, 1715,   48,  480, 2711, 2711, 2711, 2711, 2711,\n",
       "              2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711,\n",
       "              2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711,\n",
       "              2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711,\n",
       "              2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711,\n",
       "              2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711,\n",
       "              2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711])           ,\n",
       "       array([ 679,  663, 2231,  531,   50,   48,  480, 2711, 2711, 2711, 2711,\n",
       "              2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711,\n",
       "              2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711,\n",
       "              2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711,\n",
       "              2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711,\n",
       "              2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711,\n",
       "              2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711, 2711])           ],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eqs_tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "dataset_dict = {\"eqs\": eqs_tokenized, \"ans\": ans_tokenized}\n",
    "dataset = Dataset.from_dict(dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_testvalid = dataset.train_test_split(test_size=0.2)\n",
    "test_valid = train_testvalid[\"test\"].train_test_split(test_size=0.5)\n",
    "train_test_valid_dataset = DatasetDict(\n",
    "    {\n",
    "        \"train\": train_testvalid[\"train\"],\n",
    "        \"test\": test_valid[\"test\"],\n",
    "        \"valid\": test_valid[\"train\"],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_collate_fn(pad_index):\n",
    "    def collate_fn(batch):\n",
    "        batch_eqs = [example[\"eqs\"] for example in batch]\n",
    "        batch_ans = [example[\"ans\"] for example in batch]\n",
    "        batch_eqs = nn.utils.rnn.pad_sequence(batch_eqs, padding_value=pad_index)\n",
    "        batch_ans = nn.utils.rnn.pad_sequence(batch_ans, padding_value=pad_index)\n",
    "        batch = {\n",
    "            \"eqs\": batch_eqs,\n",
    "            \"ans\": batch_ans,\n",
    "            \"len_eqs\": [example[\"len_eqs\"] for example in batch],\n",
    "            \"len_ans\": [example[\"len_ans\"] for example in batch],\n",
    "        }\n",
    "        return batch\n",
    "\n",
    "    return collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data_loader(dataset, batch_size, pad_index, shuffle=False):\n",
    "    collate_fn = get_collate_fn(pad_index)\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=collate_fn,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_type = \"torch\"\n",
    "format_columns = [\"eqs\", \"ans\"]\n",
    "\n",
    "train_data = train_test_valid_dataset[\"train\"].with_format(\n",
    "    type=data_type, columns=format_columns, output_all_columns=True\n",
    ")\n",
    "\n",
    "valid_data = train_test_valid_dataset[\"valid\"].with_format(\n",
    "    type=data_type,\n",
    "    columns=format_columns,\n",
    "    output_all_columns=True,\n",
    ")\n",
    "\n",
    "test_data = train_test_valid_dataset[\"test\"].with_format(\n",
    "    type=data_type,\n",
    "    columns=format_columns,\n",
    "    output_all_columns=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9c7de26e7f3475facedc54e9f605b08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/8536 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2277feee3624614b4cea113df6ab822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/1067 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e99ee18b45eb46ff801ce85b1c9a7155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/1067 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_size(sequence):\n",
    "    for i in range(len(sequence)):\n",
    "        if sequence[i] == pad_index:\n",
    "            return i + 1\n",
    "    return len(sequence)\n",
    "\n",
    "\n",
    "train_data = train_data.add_column(\n",
    "    \"len_eqs\", [get_size(seq) for seq in list(train_data[\"eqs\"])]\n",
    ")\n",
    "train_data = train_data.add_column(\n",
    "    \"len_ans\", [get_size(seq) for seq in list(train_data[\"ans\"])]\n",
    ")\n",
    "\n",
    "valid_data = valid_data.add_column(\n",
    "    \"len_eqs\", [get_size(seq) for seq in list(valid_data[\"eqs\"])]\n",
    ")\n",
    "valid_data = valid_data.add_column(\n",
    "    \"len_ans\", [get_size(seq) for seq in list(valid_data[\"ans\"])]\n",
    ")\n",
    "\n",
    "test_data = test_data.add_column(\n",
    "    \"len_eqs\", [get_size(seq) for seq in list(test_data[\"eqs\"])]\n",
    ")\n",
    "test_data = test_data.add_column(\n",
    "    \"len_ans\", [get_size(seq) for seq in list(test_data[\"ans\"])]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_data_loader = get_data_loader(train_data, batch_size, pad_index, shuffle=True)\n",
    "valid_data_loader = get_data_loader(valid_data, batch_size, pad_index)\n",
    "test_data_loader = get_data_loader(test_data, batch_size, pad_index)\n",
    "\n",
    "# train_data_loaders[tokenization_type] = get_data_loader(train_data, batch_size, pad_index, shuffle=True)\n",
    "# valid_data_loaders[tokenization_type] = get_data_loader(valid_data, batch_size, pad_index)\n",
    "# test_data_loaders[tokenization_type] = get_data_loader(test_data, batch_size, pad_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(sequence, vocab_size):\n",
    "    tensor = torch.zeros(len(sequence), vocab_size)\n",
    "    for i, idx in enumerate(sequence):\n",
    "        tensor[i, idx] = 1\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        rnn_type,\n",
    "        input_dim,\n",
    "        embedding_dim,\n",
    "        hidden_dim,\n",
    "        n_layers,\n",
    "        dropout,\n",
    "        bidirectional=False,\n",
    "        one_hot=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.one_hot = one_hot\n",
    "        if not one_hot:\n",
    "            self.embedding = nn.Embedding(\n",
    "                input_dim, embedding_dim, padding_idx=pad_index\n",
    "            )\n",
    "        self.rnn_type = rnn_type\n",
    "        if rnn_type == \"lstm\":\n",
    "            self.rnn = nn.LSTM(\n",
    "                embedding_dim,\n",
    "                hidden_dim,\n",
    "                n_layers,\n",
    "                dropout=dropout,\n",
    "                bidirectional=bidirectional,\n",
    "            )\n",
    "        elif rnn_type == \"rnn\":\n",
    "            self.rnn = nn.RNN(\n",
    "                embedding_dim,\n",
    "                hidden_dim,\n",
    "                n_layers,\n",
    "                dropout=dropout,\n",
    "                bidirectional=bidirectional,\n",
    "            )\n",
    "        elif rnn_type == \"gru\":\n",
    "            self.rnn = nn.GRU(\n",
    "                embedding_dim,\n",
    "                hidden_dim,\n",
    "                n_layers,\n",
    "                dropout=dropout,\n",
    "                bidirectional=bidirectional,\n",
    "            )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src, src_len):\n",
    "        # src = [src length, batch size]\n",
    "        if not self.one_hot:\n",
    "            embedded = self.dropout(self.embedding(src))\n",
    "        else:\n",
    "            embedded = torch.stack(\n",
    "                [one_hot_encode(batch_sample, vocab_size) for batch_sample in src]\n",
    "            ).to(device)\n",
    "\n",
    "        # print(src_len.get_device(), embedded.get_device())\n",
    "        packed_inputs = pack_padded_sequence(\n",
    "            embedded, src_len.cpu(), enforce_sorted=False\n",
    "        )\n",
    "\n",
    "        # embedded = [src length, batch size, embedding dim]\n",
    "        if self.rnn_type == \"lstm\":\n",
    "            outputs, (hidden, cell) = self.rnn(packed_inputs)\n",
    "\n",
    "            # outputs, output_lengths = pad_packed_sequence(outputs, batch_first=True)\n",
    "            return hidden, cell\n",
    "        else:\n",
    "            outputs, hidden = self.rnn(packed_inputs)\n",
    "            return hidden\n",
    "        # outputs = [src length, batch size, hidden dim * n directions]\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # cell = [n layers * n directions, batch size, hidden dim]\n",
    "        # outputs are always from the top hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        rnn_type,\n",
    "        output_dim,\n",
    "        embedding_dim,\n",
    "        hidden_dim,\n",
    "        n_layers,\n",
    "        dropout,\n",
    "        bidirectional=False,\n",
    "        one_hot=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.rnn_type = rnn_type\n",
    "        self.one_hot = one_hot\n",
    "        if not one_hot:\n",
    "            self.embedding = nn.Embedding(\n",
    "                input_dim, embedding_dim, padding_idx=pad_index\n",
    "            )\n",
    "        self.embedding = nn.Embedding(output_dim, embedding_dim)\n",
    "        if rnn_type == \"lstm\":\n",
    "            self.rnn = nn.LSTM(\n",
    "                embedding_dim,\n",
    "                hidden_dim,\n",
    "                n_layers,\n",
    "                dropout=dropout,\n",
    "                bidirectional=bidirectional,\n",
    "            )\n",
    "        elif rnn_type == \"rnn\":\n",
    "            self.rnn = nn.RNN(\n",
    "                embedding_dim,\n",
    "                hidden_dim,\n",
    "                n_layers,\n",
    "                dropout=dropout,\n",
    "                bidirectional=bidirectional,\n",
    "            )\n",
    "        elif rnn_type == \"gru\":\n",
    "            self.rnn = nn.GRU(\n",
    "                embedding_dim,\n",
    "                hidden_dim,\n",
    "                n_layers,\n",
    "                dropout=dropout,\n",
    "                bidirectional=bidirectional,\n",
    "            )\n",
    "        if bidirectional:\n",
    "            self.fc_out = nn.Linear(2 * hidden_dim, output_dim)\n",
    "        else:\n",
    "            self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, cell=None):\n",
    "        # input = [batch size]\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # cell = [n layers * n directions, batch size, hidden dim]\n",
    "        # n directions in the decoder will both always be 1, therefore:\n",
    "        # hidden = [n layers, batch size, hidden dim]\n",
    "        # context = [n layers, batch size, hidden dim]\n",
    "        input = input.unsqueeze(0)\n",
    "        # input = [1, batch size]\n",
    "        if not self.one_hot:\n",
    "            embedded = self.dropout(self.embedding(input))\n",
    "        else:\n",
    "            embedded = torch.stack(\n",
    "                [one_hot_encode(batch_sample, vocab_size) for batch_sample in input]\n",
    "            ).to(device)\n",
    "        # embedded = [1, batch size, embedding dim]\n",
    "        if self.rnn_type == \"lstm\":\n",
    "            output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "            prediction = self.fc_out(output.squeeze(0))\n",
    "            return prediction, hidden, cell\n",
    "        else:\n",
    "            output, hidden = self.rnn(embedded, hidden)\n",
    "            prediction = self.fc_out(output.squeeze(0))\n",
    "            return prediction, hidden\n",
    "        # output = [seq length, batch size, hidden dim * n directions]\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # cell = [n layers * n directions, batch size, hidden dim]\n",
    "        # seq length and n directions will always be 1 in this decoder, therefore:\n",
    "        # output = [1, batch size, hidden dim]\n",
    "        # hidden = [n layers, batch size, hidden dim]\n",
    "        # cell = [n layers, batch size, hidden dim]\n",
    "        # prediction = self.fc_out(output.squeeze(0))\n",
    "        # prediction = [batch size, output dim]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        assert (\n",
    "            encoder.hidden_dim == decoder.hidden_dim\n",
    "        ), \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert (\n",
    "            encoder.n_layers == decoder.n_layers\n",
    "        ), \"Encoder and decoder must have equal number of layers!\"\n",
    "\n",
    "    def forward(self, src, src_len, trg, teacher_forcing_ratio):\n",
    "        # src = [src length, batch size]\n",
    "        # trg = [trg length, batch size]\n",
    "        # teacher_forcing_ratio is probability to use teacher forcing\n",
    "        # e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_length = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        # tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_length, batch_size, trg_vocab_size).to(self.device)\n",
    "        # last hidden state of the encoder is used as the initial hidden state of the decoder\n",
    "        if self.encoder.rnn_type == \"lstm\":\n",
    "            hidden, cell = self.encoder(src, src_len)\n",
    "        else:\n",
    "            hidden = self.encoder(src, src_len)\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # cell = [n layers * n directions, batch size, hidden dim]\n",
    "        # first input to the decoder is the <sos> tokens\n",
    "        input = trg[0, :]\n",
    "        # input = [batch size]\n",
    "        for t in range(1, trg_length):\n",
    "            # insert input token embedding, previous hidden and previous cell states\n",
    "            # receive output tensor (predictions) and new hidden and cell states\n",
    "            if self.encoder.rnn_type == \"lstm\":\n",
    "                output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            else:\n",
    "                output, hidden = self.decoder(input, hidden)\n",
    "            # output = [batch size, output dim]\n",
    "            # hidden = [n layers, batch size, hidden dim]\n",
    "            # cell = [n layers, batch size, hidden dim]\n",
    "            # place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            # decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            # get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1)\n",
    "            # if teacher forcing, use actual next token as next input\n",
    "            # if not, use predicted token\n",
    "            input = trg[t] if teacher_force else top1\n",
    "            # input = [batch size]\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# weight initialization\n",
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train loop\n",
    "\n",
    "\n",
    "def train_fn(\n",
    "    model, data_loader, optimizer, criterion, clip, teacher_forcing_ratio, device\n",
    "):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, batch in enumerate(tqdm(data_loader)):\n",
    "        src = batch[\"eqs\"].to(device)\n",
    "        trg = batch[\"ans\"].to(device)\n",
    "        src_len = torch.tensor(batch[\"len_eqs\"], dtype=torch.int64).to(device)\n",
    "        # src = [src length, batch size]\n",
    "        # trg = [trg length, batch size]\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, src_len, trg, teacher_forcing_ratio)\n",
    "        # output = [trg length, batch size, trg vocab size]\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        # output = [(trg length - 1) * batch size, trg vocab size]\n",
    "        trg = trg[1:].view(-1)\n",
    "        # trg = [(trg length - 1) * batch size]\n",
    "        loss = criterion(output, trg)\n",
    "        # ignore_index=pad_toke_id\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# eval loop\n",
    "\n",
    "\n",
    "def evaluate_fn(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(tqdm(data_loader)):\n",
    "            src = batch[\"eqs\"].to(device)\n",
    "            trg = batch[\"ans\"].to(device)\n",
    "            src_len = torch.tensor(batch[\"len_eqs\"]).to(device)\n",
    "            # src = [src length, batch size]\n",
    "            # trg = [trg length, batch size]\n",
    "            output = model(src, src_len, trg, 0)  # turn off teacher forcing\n",
    "            # output = [trg length, batch size, trg vocab size]\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            # output = [(trg length - 1) * batch size, trg vocab size]\n",
    "            trg = trg[1:].view(-1)\n",
    "            # trg = [(trg length - 1) * batch size]\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_eqs = [\n",
    "    \"2xy\\mathrm{d}x + (x^2 - y^2)\\mathrm{d}y = 0\",  # в полных дифференциалах\n",
    "    \"\\frac{3x^2 + y^2}{y^2}\\mathrm{d}x - \\frac{2x^3 + 5y}{y^3}\\mathrm{d}y\",  # в полных дифференциалах\n",
    "    \"y^{\\prime}=\\mathrm{tg}{\\frac{y}{x}}+{\\frac{y}{x}}\",  # однородное\n",
    "    \"y^{\\prime}=\\cos^{2}{\\frac{y}{x}}+{\\frac{y}{x}}\",  # однородное\n",
    "    \"y^{\\prime}-y={\\frac{e^{x}}{x^{2}}}\",  # линейное 1-го порядка\n",
    "    \"(2x+y^{2})y^{\\prime}=y\",  # линейное 1-го порядка\n",
    "    \"y y^{\\prime3}+x=1\",  # не разрешенное относительно производной\n",
    "    \"y^{\\prime^{3}}+y^{2}=y y^{\\prime}(y^{\\prime}+1)\",  # не разрешенное относительно производной\n",
    "    \"2y^{\\prime}-\\frac{y}{x}=\\frac{4x^{2}}{y}\",  # уравнение Бернулли\n",
    "    \"xy^{\\prime}-2y={\\frac{x}{y}}\",  # уравнение Бернулли\n",
    "    \"2y^{\\prime\\prime}+3y^{\\prime}-5y=10\",  # неоднородные линейные\n",
    "    \"y^{\\prime\\prime}-2y^{\\prime}-8y=x^{2}+3\",  # неоднородные линейные\n",
    "    \"{\\frac{x\\,d x+y\\,d y}{y\\,\\overline{{{1+x^{2}+y^{2}}}}}}+{\\frac{y\\,d x-x\\,d y}{x^{2}+y^{2}}}=0\",  # интегрирующий множитель\n",
    "    \"(x^{2}y^{2}-1)\\,d y+2x y^{3}\\,d x=0\",  # интегрирующий множитель\n",
    "]\n",
    "valid_eqs_answers = [\n",
    "    \"3x^2 - y^3 = C\",\n",
    "    \"x + \\frac{x^3}{y^2} + \\frac{5}{y} = C\",\n",
    "    \"y=x\\arcsin(C x)\",\n",
    "    \"y(x)=x\\tan^{-1}(c_{1}+\\log(x))\",\n",
    "    \"y(x)=c_{1}\\,e^{x}-{\\frac{e^{x}}{x}}\",\n",
    "    \"x=y^{2}(\\ln y + C)\",\n",
    "    \"(x-1)^{4/3}+y^{4/3}=C\",\n",
    "    \"4y=(x+C)^{2}\",\n",
    "    \"y(x)=-{\\sqrt{x}}\\;{\\sqrt{c_{1}+2x^{2}}}\",\n",
    "    \"y(x)={\\frac{\\sqrt{x}\\;{\\sqrt{c_{1}\\,x^{3}-2}}}{\\sqrt{3}}}\",\n",
    "    \"y(x)=c_{1}\\;e^{-(5x)/2}+c_{2}\\;e^{x}-2\",\n",
    "    \"y(x)=c_{1}\\;e^{-2x}+c_{2}\\;e^{4x}-{\\frac{x^{2}}{8}}+{\\frac{x}{16}}-{\\frac{27}{64}}\",\n",
    "    \"{\\sqrt{{1+x^{2}+y^{2}}}}+\\arctan{\\frac{x}{y}}=C\",\n",
    "    \"x^{2}y+{\\frac{1}{y}}=C\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "def predict_valid_eqs(model, file_name):\n",
    "    preds = []\n",
    "    for eq in valid_eqs:\n",
    "        preds.append(predict(eq, model))\n",
    "    d = dict(zip(valid_eqs_answers, preds))\n",
    "    with open(f\"valid_eqs_preds/{file_name}.pickle\", \"wb\") as handle:\n",
    "        pickle.dump(d, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def detokenize(sentence, is_eq: bool):\n",
    "    full_str = tokenizer.decode(sentence)\n",
    "    if not is_eq:\n",
    "        answer = full_str[5:]\n",
    "        end_token_idx = answer.find(\"<eos>\")\n",
    "        answer = answer[:end_token_idx]\n",
    "    else:\n",
    "        answer = full_str\n",
    "    answer = answer.replace(\"<pad>\", \"\")\n",
    "    return answer\n",
    "\n",
    "\n",
    "def tokenize(sentence, is_eq: bool):\n",
    "    if not is_eq:\n",
    "        sentence = \"<sos>\" + sentence + \"<eos>\"\n",
    "    res = tokenizer.encode(sentence)\n",
    "    while len(res) < seq_length:\n",
    "        res.append(tokenizer.encode(\"<pad>\")[0])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(\n",
    "    sentence,\n",
    "    model,\n",
    "    sentence_len=None,\n",
    "    input_is_tokenized=False,\n",
    "    device=\"cuda\",\n",
    "    max_output_length=25,\n",
    "):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if input_is_tokenized:\n",
    "            ids = sentence\n",
    "        else:\n",
    "            # ids = tokenize(sentence, is_eq=True)\n",
    "            ids = char_tokenize(sentence, True, max_token, vocab)  # char\n",
    "            sentence_len = get_size(ids)\n",
    "\n",
    "        tensor = torch.LongTensor(ids).unsqueeze(-1).to(device)\n",
    "        if model.encoder.rnn_type == \"lstm\":\n",
    "            hidden, cell = model.encoder(\n",
    "                tensor, torch.tensor([sentence_len], dtype=torch.int64)\n",
    "            )\n",
    "        else:\n",
    "            hidden = model.encoder(\n",
    "                tensor, torch.tensor([sentence_len], dtype=torch.int64)\n",
    "            )\n",
    "        inputs = [special_tokens[\"<sos>\"]]\n",
    "        for _ in range(max_output_length):\n",
    "            inputs_tensor = torch.LongTensor([inputs[-1]]).to(device)\n",
    "            if model.encoder.rnn_type == \"lstm\":\n",
    "                output, hidden, cell = model.decoder(inputs_tensor, hidden, cell)\n",
    "            else:\n",
    "                output, hidden = model.decoder(inputs_tensor, hidden)\n",
    "            predicted_token = output.argmax(-1).item()\n",
    "            inputs.append(predicted_token)\n",
    "            if predicted_token == special_tokens[\"<eos>\"]:\n",
    "                break\n",
    "        # tokens = detokenize(inputs, is_eq=False)[4:]\n",
    "        tokens = char_detokenize(inputs, inverse_vocab, special_tokens)  # char\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "\n",
    "# val_references=[detokenize(sentence.tolist(), is_eq=False) for sentence in valid_data['ans']]\n",
    "# test_references=[detokenize(sentence.tolist(), is_eq=False) for sentence in test_data['ans']]\n",
    "\n",
    "val_references = [\n",
    "    char_detokenize(sentence.tolist(), inverse_vocab, special_tokens)\n",
    "    for sentence in valid_data[\"ans\"]\n",
    "]\n",
    "test_references = [\n",
    "    char_detokenize(sentence.tolist(), inverse_vocab, special_tokens)\n",
    "    for sentence in test_data[\"ans\"]\n",
    "]\n",
    "\n",
    "\n",
    "def bleu_score(preds, refs):\n",
    "    return bleu.compute(predictions=preds, references=refs)[\"bleu\"]\n",
    "\n",
    "\n",
    "def accuracy(preds, refs):\n",
    "    equal_count = 0\n",
    "    for i in range(len(refs)):\n",
    "        if preds[i] == refs[i]:\n",
    "            equal_count += 1\n",
    "    return equal_count / len(refs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# result saving\n",
    "\n",
    "result = {\n",
    "    \"rnn_type\": [],\n",
    "    \"optimizer\": [],\n",
    "    \"bidirectional\": [],\n",
    "    \"hidden_dim\": [],\n",
    "    \"n_layers\": [],\n",
    "    \"learning_rate\": [],\n",
    "    \"teacher_forcing_ratio\": [],\n",
    "    \"epoch\": [],\n",
    "    \"val_bleu\": [],\n",
    "    \"val_accuracy\": [],\n",
    "    \"test_bleu\": [],\n",
    "    \"test_accuracy\": [],\n",
    "}\n",
    "\n",
    "\n",
    "def update_result():\n",
    "    result[\"rnn_type\"].append(rnn_type)\n",
    "    result[\"teacher_forcing_ratio\"].append(teacher_forcing_ratio)\n",
    "    result[\"optimizer\"].append(optimizer_name)\n",
    "    result[\"bidirectional\"].append(bidirectional)\n",
    "    result[\"n_layers\"].append(n_layers)\n",
    "    result[\"hidden_dim\"].append(hidden_dim)\n",
    "    result[\"learning_rate\"].append(lr)\n",
    "    result[\"epoch\"].append(epoch + 1)\n",
    "    result[\"val_bleu\"].append(round(val_bleu, 3))\n",
    "    result[\"test_bleu\"].append(round(test_bleu, 3))\n",
    "    result[\"val_accuracy\"].append(round(val_accuracy, 3))\n",
    "    result[\"test_accuracy\"].append(round(test_accuracy, 3))\n",
    "\n",
    "    res_df = pd.DataFrame(result)\n",
    "    res_df.to_csv(\"results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 590,756 trainable parameters\n",
      "EPOCH 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [00:28<00:00,  2.36it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   3.001 | Train PPL:  20.108\n",
      "\tValid Loss:   2.352 | Valid PPL:  10.501\n",
      "\tValid BLEU:   0.042 | Valid Accuracy:   0.000\n",
      "EPOCH 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [00:28<00:00,  2.37it/s]\n",
      "100%|██████████| 9/9 [00:02<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   2.163 | Train PPL:   8.696\n",
      "\tValid Loss:   1.991 | Valid PPL:   7.325\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 92\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mValid Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m7.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Valid PPL: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mexp(valid_loss)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m7.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# compute metrics\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m val_predictions \u001b[38;5;241m=\u001b[39m [predict(valid_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meqs\u001b[39m\u001b[38;5;124m'\u001b[39m][i], model, valid_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlen_eqs\u001b[39m\u001b[38;5;124m'\u001b[39m][i], \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(valid_data))]\n\u001b[1;32m     93\u001b[0m test_predictions \u001b[38;5;241m=\u001b[39m [predict(test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meqs\u001b[39m\u001b[38;5;124m'\u001b[39m][i], model, test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlen_eqs\u001b[39m\u001b[38;5;124m'\u001b[39m][i], \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(test_data))]\n\u001b[1;32m     94\u001b[0m val_bleu \u001b[38;5;241m=\u001b[39m bleu_score(preds\u001b[38;5;241m=\u001b[39mval_predictions, refs\u001b[38;5;241m=\u001b[39mval_references)\n",
      "Cell \u001b[0;32mIn[36], line 92\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mValid Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m7.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Valid PPL: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mexp(valid_loss)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m7.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# compute metrics\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m val_predictions \u001b[38;5;241m=\u001b[39m [\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalid_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meqs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlen_eqs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(valid_data))]\n\u001b[1;32m     93\u001b[0m test_predictions \u001b[38;5;241m=\u001b[39m [predict(test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meqs\u001b[39m\u001b[38;5;124m'\u001b[39m][i], model, test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlen_eqs\u001b[39m\u001b[38;5;124m'\u001b[39m][i], \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(test_data))]\n\u001b[1;32m     94\u001b[0m val_bleu \u001b[38;5;241m=\u001b[39m bleu_score(preds\u001b[38;5;241m=\u001b[39mval_predictions, refs\u001b[38;5;241m=\u001b[39mval_references)\n",
      "Cell \u001b[0;32mIn[30], line 22\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(sentence, model, sentence_len, input_is_tokenized, device, max_output_length)\u001b[0m\n\u001b[1;32m     20\u001b[0m     hidden, cell \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencoder(tensor, torch\u001b[38;5;241m.\u001b[39mtensor([sentence_len], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint64))\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 22\u001b[0m     hidden \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43msentence_len\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint64\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m inputs \u001b[38;5;241m=\u001b[39m [special_tokens[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<sos>\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_output_length):\n",
      "File \u001b[0;32m/opt/miniconda3/envs/hugging_face/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[20], line 37\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, src, src_len)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden, cell\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 37\u001b[0m     outputs, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpacked_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden\n",
      "File \u001b[0;32m/opt/miniconda3/envs/hugging_face/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/miniconda3/envs/hugging_face/lib/python3.9/site-packages/torch/nn/modules/rnn.py:485\u001b[0m, in \u001b[0;36mRNN.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRNN_TANH\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 485\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn_tanh\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m                              \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m                              \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    489\u001b[0m         result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mrnn_relu(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    490\u001b[0m                               \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining,\n\u001b[1;32m    491\u001b[0m                               \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_dim = vocab_size\n",
    "output_dim = vocab_size\n",
    "# encoder_embedding_dim = 256\n",
    "# decoder_embedding_dim = 256\n",
    "# encoder_embedding_dim = max_len\n",
    "# decoder_embedding_dim = max_len\n",
    "encoder_dropout = 0.5\n",
    "decoder_dropout = 0.5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device='cpu'\n",
    "\n",
    "rnn_type_options = [\"rnn\", \"gru\", \"lstm\"]\n",
    "optimizer_options = [\"Adam\", \"AdamW\"]\n",
    "teacher_forcing_ratio_options = [0.1, 0.3, 0.5, 0.7]\n",
    "lr_options = [0.0001, 0.001, 0.01, 0.1]\n",
    "n_layers_options = [2, 4, 6, 8]\n",
    "hidden_dim_options = [256, 512, 1024]\n",
    "for rnn_type in rnn_type_options:\n",
    "    for teacher_forcing_ratio in teacher_forcing_ratio_options:\n",
    "        for optimizer_name in optimizer_options:\n",
    "            for bidirectional in [False, True]:\n",
    "                for hidden_dim in hidden_dim_options:\n",
    "                    for n_layers in n_layers_options:\n",
    "                        for lr in lr_options:\n",
    "                            for one_hot in [False, True]:\n",
    "                                if one_hot:\n",
    "                                    encoder_embedding_dim = vocab_size\n",
    "                                    decoder_embedding_dim = vocab_size\n",
    "                                else:\n",
    "                                    encoder_embedding_dim = max_len\n",
    "                                    decoder_embedding_dim = max_len\n",
    "                                encoder = Encoder(\n",
    "                                    rnn_type,\n",
    "                                    input_dim,\n",
    "                                    encoder_embedding_dim,\n",
    "                                    hidden_dim,\n",
    "                                    n_layers,\n",
    "                                    encoder_dropout,\n",
    "                                    bidirectional,\n",
    "                                    one_hot=one_hot,\n",
    "                                )\n",
    "\n",
    "                                decoder = Decoder(\n",
    "                                    rnn_type,\n",
    "                                    output_dim,\n",
    "                                    decoder_embedding_dim,\n",
    "                                    hidden_dim,\n",
    "                                    n_layers,\n",
    "                                    decoder_dropout,\n",
    "                                    bidirectional,\n",
    "                                    one_hot=one_hot,\n",
    "                                )\n",
    "\n",
    "                                model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "                                model.apply(init_weights)\n",
    "                                print(\n",
    "                                    f\"The model has {count_parameters(model):,} trainable parameters\"\n",
    "                                )\n",
    "\n",
    "                                if optimizer_name == \"Adam\":\n",
    "                                    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "                                else:\n",
    "                                    optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "                                criterion = nn.CrossEntropyLoss(ignore_index=pad_index)\n",
    "\n",
    "                                n_epochs = 6\n",
    "                                clip = 1.0\n",
    "                                best_valid_loss = float(\"inf\")\n",
    "                                for epoch in range(n_epochs):\n",
    "                                    print(f\"EPOCH {epoch+1}\")\n",
    "                                    unique_name = f\"type-{rnn_type}_optim-{optimizer_name}__teacher-forcing-{teacher_forcing_ratio}_bidir-{int(bidirectional)}_hiddim-{hidden_dim}_layers-{n_layers}_lr-{lr}_onehot-{onehot}_epoch-{epoch+1}\"\n",
    "                                    train_loss = train_fn(\n",
    "                                        model,\n",
    "                                        train_data_loader,\n",
    "                                        optimizer,\n",
    "                                        criterion,\n",
    "                                        clip,\n",
    "                                        teacher_forcing_ratio,\n",
    "                                        device,\n",
    "                                    )\n",
    "                                    valid_loss = evaluate_fn(\n",
    "                                        model,\n",
    "                                        valid_data_loader,\n",
    "                                        criterion,\n",
    "                                        device,\n",
    "                                    )\n",
    "                                    if valid_loss < best_valid_loss:\n",
    "                                        best_valid_loss = valid_loss\n",
    "                                        torch.save(\n",
    "                                            model.state_dict(),\n",
    "                                            f\"encoder_decoder_models/model_{unique_name}.pt\",\n",
    "                                        )\n",
    "                                    print(\n",
    "                                        f\"\\tTrain Loss: {train_loss:7.3f} | Train PPL: {np.exp(train_loss):7.3f}\"\n",
    "                                    )\n",
    "                                    print(\n",
    "                                        f\"\\tValid Loss: {valid_loss:7.3f} | Valid PPL: {np.exp(valid_loss):7.3f}\"\n",
    "                                    )\n",
    "\n",
    "                                    # compute metrics\n",
    "                                    val_predictions = [\n",
    "                                        predict(\n",
    "                                            valid_data[\"eqs\"][i],\n",
    "                                            model,\n",
    "                                            valid_data[\"len_eqs\"][i],\n",
    "                                            True,\n",
    "                                        )\n",
    "                                        for i in range(len(valid_data))\n",
    "                                    ]\n",
    "                                    test_predictions = [\n",
    "                                        predict(\n",
    "                                            test_data[\"eqs\"][i],\n",
    "                                            model,\n",
    "                                            test_data[\"len_eqs\"][i],\n",
    "                                            True,\n",
    "                                        )\n",
    "                                        for i in range(len(test_data))\n",
    "                                    ]\n",
    "                                    val_bleu = bleu_score(\n",
    "                                        preds=val_predictions, refs=val_references\n",
    "                                    )\n",
    "                                    test_bleu = bleu_score(\n",
    "                                        preds=test_predictions, refs=test_references\n",
    "                                    )\n",
    "                                    val_accuracy = accuracy(\n",
    "                                        preds=val_predictions, refs=val_references\n",
    "                                    )\n",
    "                                    test_accuracy = accuracy(\n",
    "                                        preds=test_predictions, refs=test_references\n",
    "                                    )\n",
    "\n",
    "                                    # save preds on valid_eqs\n",
    "                                    predict_valid_eqs(model, f\"pred_{unique_name}\")\n",
    "\n",
    "                                    print(\n",
    "                                        f\"\\tValid BLEU: {val_bleu:7.3f} | Valid Accuracy: {val_accuracy:7.3f}\"\n",
    "                                    )\n",
    "                                    update_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Hugging Face)",
   "language": "python",
   "name": "python_hf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
