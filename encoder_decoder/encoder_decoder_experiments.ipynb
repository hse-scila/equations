{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "import datasets\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(1, \"minbpe-master\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"pairs_dataset.csv\")\n",
    "df2 = pd.read_csv(\"generated_pairs.csv\")\n",
    "df = pd.concat([df1, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add special tokens\n",
    "lines = \"<sos>\" + df[\"equation\"] + \" \" + df[\"answer\"] + \"<eos>\"\n",
    "str_for_vocab_training = lines.str.cat(sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from minbpe import BasicTokenizer\n",
    "\n",
    "VOCAB_SIZE = 4096\n",
    "\n",
    "tokenizer = BasicTokenizer()\n",
    "# doesn't allow adding special tokens; make it learn <pad>\n",
    "str_for_vocab_training += \"<pad>\" * 10\n",
    "tokenizer.train(str_for_vocab_training, vocab_size=VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# eq_lines = \"<sos>\" + df[\"equation\"] + \"<eos>\"\n",
    "eq_lines = df[\"equation\"]\n",
    "ans_lines = \"<sos>\" + df[\"answer\"] + \"<eos>\"\n",
    "eqs_tokenized = np.array(eq_lines.apply(lambda line: list(tokenizer.encode(line))))\n",
    "ans_tokenized = np.array(ans_lines.apply(lambda line: list(tokenizer.encode(line))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seq_length = max(\n",
    "    len(max(eqs_tokenized, key=len)), len(max(ans_tokenized, key=len))\n",
    ")  # max seq len\n",
    "\n",
    "\n",
    "def pad(lines_tokenized_basic):\n",
    "    for i in range(len(lines_tokenized_basic)):\n",
    "        while len(lines_tokenized_basic[i]) < seq_length:\n",
    "            lines_tokenized_basic[i].append(tokenizer.encode(\"<pad>\")[0])\n",
    "        lines_tokenized_basic[i] = np.array(lines_tokenized_basic[i])\n",
    "    lines_tokenized_basic = np.array(lines_tokenized_basic)\n",
    "    return lines_tokenized_basic\n",
    "\n",
    "\n",
    "eqs_tokenized = pad(eqs_tokenized)\n",
    "ans_tokenized = pad(ans_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(eqs_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "dataset_dict = {\"eqs\": eqs_tokenized, \"ans\": ans_tokenized}\n",
    "dataset = Dataset.from_dict(dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_testvalid = dataset.train_test_split(test_size=0.2)\n",
    "test_valid = train_testvalid[\"test\"].train_test_split(test_size=0.5)\n",
    "train_test_valid_dataset = DatasetDict(\n",
    "    {\n",
    "        \"train\": train_testvalid[\"train\"],\n",
    "        \"test\": test_valid[\"test\"],\n",
    "        \"valid\": test_valid[\"train\"],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pad_index = tokenizer.encode(\"<pad>\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_collate_fn(pad_index):\n",
    "    def collate_fn(batch):\n",
    "        batch_eqs = [example[\"eqs\"] for example in batch]\n",
    "        batch_ans = [example[\"ans\"] for example in batch]\n",
    "        batch_eqs = nn.utils.rnn.pad_sequence(batch_eqs, padding_value=pad_index)\n",
    "        batch_ans = nn.utils.rnn.pad_sequence(batch_ans, padding_value=pad_index)\n",
    "        batch = {\n",
    "            \"eqs\": batch_eqs,\n",
    "            \"ans\": batch_ans,\n",
    "        }\n",
    "        return batch\n",
    "\n",
    "    return collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data_loader(dataset, batch_size, pad_index, shuffle=False):\n",
    "    collate_fn = get_collate_fn(pad_index)\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=collate_fn,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_type = \"torch\"\n",
    "format_columns = [\"eqs\", \"ans\"]\n",
    "\n",
    "train_data = train_test_valid_dataset[\"train\"].with_format(\n",
    "    type=data_type, columns=format_columns, output_all_columns=True\n",
    ")\n",
    "\n",
    "valid_data = train_test_valid_dataset[\"valid\"].with_format(\n",
    "    type=data_type,\n",
    "    columns=format_columns,\n",
    "    output_all_columns=True,\n",
    ")\n",
    "\n",
    "test_data = train_test_valid_dataset[\"test\"].with_format(\n",
    "    type=data_type,\n",
    "    columns=format_columns,\n",
    "    output_all_columns=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_data_loader = get_data_loader(train_data, batch_size, pad_index, shuffle=True)\n",
    "valid_data_loader = get_data_loader(valid_data, batch_size, pad_index)\n",
    "test_data_loader = get_data_loader(test_data, batch_size, pad_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        rnn_type,\n",
    "        input_dim,\n",
    "        embedding_dim,\n",
    "        hidden_dim,\n",
    "        n_layers,\n",
    "        dropout,\n",
    "        bidirectional=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn_type = rnn_type\n",
    "        if rnn_type == \"lstm\":\n",
    "            self.rnn = nn.LSTM(\n",
    "                embedding_dim,\n",
    "                hidden_dim,\n",
    "                n_layers,\n",
    "                dropout=dropout,\n",
    "                bidirectional=bidirectional,\n",
    "            )\n",
    "        elif rnn_type == \"rnn\":\n",
    "            self.rnn = nn.RNN(\n",
    "                embedding_dim,\n",
    "                hidden_dim,\n",
    "                n_layers,\n",
    "                dropout=dropout,\n",
    "                bidirectional=bidirectional,\n",
    "            )\n",
    "        elif rnn_type == \"gru\":\n",
    "            self.rnn = nn.GRU(\n",
    "                embedding_dim,\n",
    "                hidden_dim,\n",
    "                n_layers,\n",
    "                dropout=dropout,\n",
    "                bidirectional=bidirectional,\n",
    "            )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        # src = [src length, batch size]\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        # embedded = [src length, batch size, embedding dim]\n",
    "        if self.rnn_type == \"lstm\":\n",
    "            outputs, (hidden, cell) = self.rnn(embedded)\n",
    "            return hidden, cell\n",
    "        else:\n",
    "            outputs, hidden = self.rnn(embedded)\n",
    "            return hidden\n",
    "        # outputs = [src length, batch size, hidden dim * n directions]\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # cell = [n layers * n directions, batch size, hidden dim]\n",
    "        # outputs are always from the top hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        rnn_type,\n",
    "        output_dim,\n",
    "        embedding_dim,\n",
    "        hidden_dim,\n",
    "        n_layers,\n",
    "        dropout,\n",
    "        bidirectional=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.rnn_type = rnn_type\n",
    "        self.embedding = nn.Embedding(output_dim, embedding_dim)\n",
    "        if rnn_type == \"lstm\":\n",
    "            self.rnn = nn.LSTM(\n",
    "                embedding_dim,\n",
    "                hidden_dim,\n",
    "                n_layers,\n",
    "                dropout=dropout,\n",
    "                bidirectional=bidirectional,\n",
    "            )\n",
    "        elif rnn_type == \"rnn\":\n",
    "            self.rnn = nn.RNN(\n",
    "                embedding_dim,\n",
    "                hidden_dim,\n",
    "                n_layers,\n",
    "                dropout=dropout,\n",
    "                bidirectional=bidirectional,\n",
    "            )\n",
    "        elif rnn_type == \"gru\":\n",
    "            self.rnn = nn.GRU(\n",
    "                embedding_dim,\n",
    "                hidden_dim,\n",
    "                n_layers,\n",
    "                dropout=dropout,\n",
    "                bidirectional=bidirectional,\n",
    "            )\n",
    "        if bidirectional:\n",
    "            self.fc_out = nn.Linear(2 * hidden_dim, output_dim)\n",
    "        else:\n",
    "            self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, cell=None):\n",
    "        # input = [batch size]\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # cell = [n layers * n directions, batch size, hidden dim]\n",
    "        # n directions in the decoder will both always be 1, therefore:\n",
    "        # hidden = [n layers, batch size, hidden dim]\n",
    "        # context = [n layers, batch size, hidden dim]\n",
    "        input = input.unsqueeze(0)\n",
    "        # input = [1, batch size]\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        # embedded = [1, batch size, embedding dim]\n",
    "        if self.rnn_type == \"lstm\":\n",
    "            output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "            prediction = self.fc_out(output.squeeze(0))\n",
    "            return prediction, hidden, cell\n",
    "        else:\n",
    "            output, hidden = self.rnn(embedded, hidden)\n",
    "            prediction = self.fc_out(output.squeeze(0))\n",
    "            return prediction, hidden\n",
    "        # output = [seq length, batch size, hidden dim * n directions]\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # cell = [n layers * n directions, batch size, hidden dim]\n",
    "        # seq length and n directions will always be 1 in this decoder, therefore:\n",
    "        # output = [1, batch size, hidden dim]\n",
    "        # hidden = [n layers, batch size, hidden dim]\n",
    "        # cell = [n layers, batch size, hidden dim]\n",
    "        # prediction = self.fc_out(output.squeeze(0))\n",
    "        # prediction = [batch size, output dim]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        assert (\n",
    "            encoder.hidden_dim == decoder.hidden_dim\n",
    "        ), \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert (\n",
    "            encoder.n_layers == decoder.n_layers\n",
    "        ), \"Encoder and decoder must have equal number of layers!\"\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio):\n",
    "        # src = [src length, batch size]\n",
    "        # trg = [trg length, batch size]\n",
    "        # teacher_forcing_ratio is probability to use teacher forcing\n",
    "        # e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_length = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        # tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_length, batch_size, trg_vocab_size).to(self.device)\n",
    "        # last hidden state of the encoder is used as the initial hidden state of the decoder\n",
    "        if self.encoder.rnn_type == \"lstm\":\n",
    "            hidden, cell = self.encoder(src)\n",
    "        else:\n",
    "            hidden = self.encoder(src)\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # cell = [n layers * n directions, batch size, hidden dim]\n",
    "        # first input to the decoder is the <sos> tokens\n",
    "        input = trg[0, :]\n",
    "        # input = [batch size]\n",
    "        for t in range(1, trg_length):\n",
    "            # insert input token embedding, previous hidden and previous cell states\n",
    "            # receive output tensor (predictions) and new hidden and cell states\n",
    "            if self.encoder.rnn_type == \"lstm\":\n",
    "                output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            else:\n",
    "                output, hidden = self.decoder(input, hidden)\n",
    "            # output = [batch size, output dim]\n",
    "            # hidden = [n layers, batch size, hidden dim]\n",
    "            # cell = [n layers, batch size, hidden dim]\n",
    "            # place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            # decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            # get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1)\n",
    "            # if teacher forcing, use actual next token as next input\n",
    "            # if not, use predicted token\n",
    "            input = trg[t] if teacher_force else top1\n",
    "            # input = [batch size]\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# weight initialization\n",
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train loop\n",
    "\n",
    "\n",
    "def train_fn(\n",
    "    model, data_loader, optimizer, criterion, clip, teacher_forcing_ratio, device\n",
    "):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, batch in enumerate(tqdm.tqdm(data_loader)):\n",
    "        src = batch[\"eqs\"].to(device)\n",
    "        trg = batch[\"ans\"].to(device)\n",
    "        # src = [src length, batch size]\n",
    "        # trg = [trg length, batch size]\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg, teacher_forcing_ratio)\n",
    "        # output = [trg length, batch size, trg vocab size]\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        # output = [(trg length - 1) * batch size, trg vocab size]\n",
    "        trg = trg[1:].view(-1)\n",
    "        # trg = [(trg length - 1) * batch size]\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# eval loop\n",
    "\n",
    "\n",
    "def evaluate_fn(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(data_loader):\n",
    "            src = batch[\"eqs\"].to(device)\n",
    "            trg = batch[\"ans\"].to(device)\n",
    "            # src = [src length, batch size]\n",
    "            # trg = [trg length, batch size]\n",
    "            output = model(src, trg, 0)  # turn off teacher forcing\n",
    "            # output = [trg length, batch size, trg vocab size]\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            # output = [(trg length - 1) * batch size, trg vocab size]\n",
    "            trg = trg[1:].view(-1)\n",
    "            # trg = [(trg length - 1) * batch size]\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_eqs = [\n",
    "    \"2xy\\mathrm{d}x + (x^2 - y^2)\\mathrm{d}y = 0\",  # в полных дифференциалах\n",
    "    \"\\frac{3x^2 + y^2}{y^2}\\mathrm{d}x - \\frac{2x^3 + 5y}{y^3}\\mathrm{d}y\",  # в полных дифференциалах\n",
    "    \"y^{\\prime}=\\mathrm{tg}{\\frac{y}{x}}+{\\frac{y}{x}}\",  # однородное\n",
    "    \"y^{\\prime}=\\cos^{2}{\\frac{y}{x}}+{\\frac{y}{x}}\",  # однородное\n",
    "    \"y^{\\prime}-y={\\frac{e^{x}}{x^{2}}}\",  # линейное 1-го порядка\n",
    "    \"(2x+y^{2})y^{\\prime}=y\",  # линейное 1-го порядка\n",
    "    \"y y^{\\prime3}+x=1\",  # не разрешенное относительно производной\n",
    "    \"y^{\\prime^{3}}+y^{2}=y y^{\\prime}(y^{\\prime}+1)\",  # не разрешенное относительно производной\n",
    "    \"2y^{\\prime}-\\frac{y}{x}=\\frac{4x^{2}}{y}\",  # уравнение Бернулли\n",
    "    \"xy^{\\prime}-2y={\\frac{x}{y}}\",  # уравнение Бернулли\n",
    "    \"2y^{\\prime\\prime}+3y^{\\prime}-5y=10\",  # неоднородные линейные\n",
    "    \"y^{\\prime\\prime}-2y^{\\prime}-8y=x^{2}+3\",  # неоднородные линейные\n",
    "    \"{\\frac{x\\,d x+y\\,d y}{y\\,\\overline{{{1+x^{2}+y^{2}}}}}}+{\\frac{y\\,d x-x\\,d y}{x^{2}+y^{2}}}=0\",  # интегрирующий множитель\n",
    "    \"(x^{2}y^{2}-1)\\,d y+2x y^{3}\\,d x=0\",  # интегрирующий множитель\n",
    "]\n",
    "valid_eqs_answers = [\n",
    "    \"3x^2 - y^3 = C\",\n",
    "    \"x + \\frac{x^3}{y^2} + \\frac{5}{y} = C\",\n",
    "    \"y=x\\arcsin(C x)\",\n",
    "    \"y(x)=x\\tan^{-1}(c_{1}+\\log(x))\",\n",
    "    \"y(x)=c_{1}\\,e^{x}-{\\frac{e^{x}}{x}}\",\n",
    "    \"x=y^{2}(\\ln y + C)\",\n",
    "    \"(x-1)^{4/3}+y^{4/3}=C\",\n",
    "    \"4y=(x+C)^{2}\",\n",
    "    \"y(x)=-{\\sqrt{x}}\\;{\\sqrt{c_{1}+2x^{2}}}\",\n",
    "    \"y(x)={\\frac{\\sqrt{x}\\;{\\sqrt{c_{1}\\,x^{3}-2}}}{\\sqrt{3}}}\",\n",
    "    \"y(x)=c_{1}\\;e^{-(5x)/2}+c_{2}\\;e^{x}-2\",\n",
    "    \"y(x)=c_{1}\\;e^{-2x}+c_{2}\\;e^{4x}-{\\frac{x^{2}}{8}}+{\\frac{x}{16}}-{\\frac{27}{64}}\",\n",
    "    \"{\\sqrt{{1+x^{2}+y^{2}}}}+\\arctan{\\frac{x}{y}}=C\",\n",
    "    \"x^{2}y+{\\frac{1}{y}}=C\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "def predict_valid_eqs(model, file_name):\n",
    "    preds = []\n",
    "    for eq in valid_eqs:\n",
    "        preds.append(predict(eq, model))\n",
    "    d = dict(zip(valid_eqs_answers, preds))\n",
    "    with open(f\"valid_eqs_preds/{file_name}.pickle\", \"wb\") as handle:\n",
    "        pickle.dump(d, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def detokenize(sentence, is_eq: bool):\n",
    "    full_str = tokenizer.decode(sentence)\n",
    "    if not is_eq:\n",
    "        answer = full_str[5:]\n",
    "        end_token_idx = answer.find(\"<eos>\")\n",
    "        answer = answer[:end_token_idx]\n",
    "    else:\n",
    "        answer = full_str\n",
    "    answer = answer.replace(\"<pad>\", \"\")\n",
    "    return answer\n",
    "\n",
    "\n",
    "def tokenize(sentence, is_eq: bool):\n",
    "    if not is_eq:\n",
    "        sentence = \"<sos>\" + sentence + \"<eos>\"\n",
    "    res = tokenizer.encode(sentence)\n",
    "    while len(res) < seq_length:\n",
    "        res.append(tokenizer.encode(\"<pad>\")[0])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(\n",
    "    sentence,\n",
    "    model,\n",
    "    input_is_tokenized=False,\n",
    "    device=\"cuda\",\n",
    "    max_output_length=25,\n",
    "):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if input_is_tokenized:\n",
    "            ids = sentence\n",
    "        else:\n",
    "            ids = tokenize(sentence, is_eq=True)\n",
    "        tensor = torch.LongTensor(ids).unsqueeze(-1).to(device)\n",
    "        if model.encoder.rnn_type == \"lstm\":\n",
    "            hidden, cell = model.encoder(tensor)\n",
    "        else:\n",
    "            hidden = model.encoder(tensor)\n",
    "        inputs = tokenizer.encode(\"<sos>\")\n",
    "        for _ in range(max_output_length):\n",
    "            inputs_tensor = torch.LongTensor([inputs[-1]]).to(device)\n",
    "            if model.encoder.rnn_type == \"lstm\":\n",
    "                output, hidden, cell = model.decoder(inputs_tensor, hidden, cell)\n",
    "            else:\n",
    "                output, hidden = model.decoder(inputs_tensor, hidden)\n",
    "            predicted_token = output.argmax(-1).item()\n",
    "            inputs.append(predicted_token)\n",
    "            if predicted_token == tokenizer.encode(\"<eos>\")[0]:\n",
    "                break\n",
    "        tokens = detokenize(inputs, is_eq=False)[4:]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "\n",
    "val_references = [\n",
    "    detokenize(sentence.tolist(), is_eq=False) for sentence in valid_data[\"ans\"]\n",
    "]\n",
    "test_references = [\n",
    "    detokenize(sentence.tolist(), is_eq=False) for sentence in test_data[\"ans\"]\n",
    "]\n",
    "\n",
    "\n",
    "def bleu_score(preds, refs):\n",
    "    return bleu.compute(predictions=preds, references=refs)[\"bleu\"]\n",
    "\n",
    "\n",
    "def accuracy(preds, refs):\n",
    "    equal_count = 0\n",
    "    for i in range(len(refs)):\n",
    "        if preds[i] == refs[i]:\n",
    "            equal_count += 1\n",
    "    return equal_count / len(refs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# result saving\n",
    "\n",
    "result = {\n",
    "    \"rnn_type\": [],\n",
    "    \"optimizer\": [],\n",
    "    \"bidirectional\": [],\n",
    "    \"hidden_dim\": [],\n",
    "    \"n_layers\": [],\n",
    "    \"learning_rate\": [],\n",
    "    \"teacher_forcing_ratio\": [],\n",
    "    \"epoch\": [],\n",
    "    \"val_bleu\": [],\n",
    "    \"val_accuracy\": [],\n",
    "    \"test_bleu\": [],\n",
    "    \"test_accuracy\": [],\n",
    "}\n",
    "\n",
    "\n",
    "def update_result():\n",
    "    result[\"rnn_type\"].append(rnn_type)\n",
    "    result[\"teacher_forcing_ratio\"].append(teacher_forcing_ratio)\n",
    "    result[\"optimizer\"].append(optimizer_name)\n",
    "    result[\"bidirectional\"].append(bidirectional)\n",
    "    result[\"n_layers\"].append(n_layers)\n",
    "    result[\"hidden_dim\"].append(hidden_dim)\n",
    "    result[\"learning_rate\"].append(lr)\n",
    "    result[\"epoch\"].append(epoch + 1)\n",
    "    result[\"val_bleu\"].append(round(val_bleu, 3))\n",
    "    result[\"test_bleu\"].append(round(test_bleu, 3))\n",
    "    result[\"val_accuracy\"].append(round(val_accuracy, 3))\n",
    "    result[\"test_accuracy\"].append(round(test_accuracy, 3))\n",
    "\n",
    "    res_df = pd.DataFrame(result)\n",
    "    res_df.to_csv(\"results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_dim = VOCAB_SIZE\n",
    "output_dim = VOCAB_SIZE\n",
    "encoder_embedding_dim = 256\n",
    "decoder_embedding_dim = 256\n",
    "encoder_dropout = 0.5\n",
    "decoder_dropout = 0.5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "rnn_type_options = [\"rnn\", \"gru\", \"lstm\"]\n",
    "optimizer_options = [\"Adam\", \"AdamW\"]\n",
    "teacher_forcing_ratio_options = [0.1, 0.3, 0.5, 0.7]\n",
    "lr_options = [0.0001, 0.001, 0.01, 0.1]\n",
    "n_layers_options = [2, 4, 6, 8]\n",
    "hidden_dim_options = [256, 512, 1024]\n",
    "for rnn_type in rnn_type_options:\n",
    "    for teacher_forcing_ratio in teacher_forcing_ratio_options:\n",
    "        for optimizer_name in optimizer_options:\n",
    "            for bidirectional in [False, True]:\n",
    "                for hidden_dim in hidden_dim_options:\n",
    "                    for n_layers in n_layers_options:\n",
    "                        for lr in lr_options:\n",
    "                            encoder = Encoder(\n",
    "                                rnn_type,\n",
    "                                input_dim,\n",
    "                                encoder_embedding_dim,\n",
    "                                hidden_dim,\n",
    "                                n_layers,\n",
    "                                encoder_dropout,\n",
    "                                bidirectional,\n",
    "                            )\n",
    "\n",
    "                            decoder = Decoder(\n",
    "                                rnn_type,\n",
    "                                output_dim,\n",
    "                                decoder_embedding_dim,\n",
    "                                hidden_dim,\n",
    "                                n_layers,\n",
    "                                decoder_dropout,\n",
    "                                bidirectional,\n",
    "                            )\n",
    "\n",
    "                            model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "                            model.apply(init_weights)\n",
    "                            print(\n",
    "                                f\"The model has {count_parameters(model):,} trainable parameters\"\n",
    "                            )\n",
    "\n",
    "                            if optimizer_name == \"Adam\":\n",
    "                                optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "                            else:\n",
    "                                optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "                            criterion = nn.CrossEntropyLoss(ignore_index=pad_index)\n",
    "\n",
    "                            n_epochs = 6\n",
    "                            clip = 1.0\n",
    "                            best_valid_loss = float(\"inf\")\n",
    "                            for epoch in range(n_epochs):\n",
    "                                print(f\"EPOCH {epoch+1}\")\n",
    "                                unique_name = f\"type-{rnn_type}_optim-{optimizer_name}__teacher-forcing-{teacher_forcing_ratio}_bidir-{int(bidirectional)}_hiddim-{hidden_dim}_layers-{n_layers}_lr-{lr}_epoch-{epoch+1}\"\n",
    "                                train_loss = train_fn(\n",
    "                                    model,\n",
    "                                    train_data_loader,\n",
    "                                    optimizer,\n",
    "                                    criterion,\n",
    "                                    clip,\n",
    "                                    teacher_forcing_ratio,\n",
    "                                    device,\n",
    "                                )\n",
    "                                valid_loss = evaluate_fn(\n",
    "                                    model,\n",
    "                                    valid_data_loader,\n",
    "                                    criterion,\n",
    "                                    device,\n",
    "                                )\n",
    "                                if valid_loss < best_valid_loss:\n",
    "                                    best_valid_loss = valid_loss\n",
    "                                    torch.save(\n",
    "                                        model.state_dict(),\n",
    "                                        f\"encoder_decoder_models/model_{unique_name}.pt\",\n",
    "                                    )\n",
    "                                print(\n",
    "                                    f\"\\tTrain Loss: {train_loss:7.3f} | Train PPL: {np.exp(train_loss):7.3f}\"\n",
    "                                )\n",
    "                                print(\n",
    "                                    f\"\\tValid Loss: {valid_loss:7.3f} | Valid PPL: {np.exp(valid_loss):7.3f}\"\n",
    "                                )\n",
    "\n",
    "                                # compute metrics\n",
    "                                val_predictions = [\n",
    "                                    predict(sentence, model, True)\n",
    "                                    for sentence in valid_data[\"eqs\"]\n",
    "                                ]\n",
    "                                test_predictions = [\n",
    "                                    predict(sentence, model, True)\n",
    "                                    for sentence in test_data[\"eqs\"]\n",
    "                                ]\n",
    "                                val_bleu = bleu_score(\n",
    "                                    preds=val_predictions, refs=val_references\n",
    "                                )\n",
    "                                test_bleu = bleu_score(\n",
    "                                    preds=test_predictions, refs=test_references\n",
    "                                )\n",
    "                                val_accuracy = accuracy(\n",
    "                                    preds=val_predictions, refs=val_references\n",
    "                                )\n",
    "                                test_accuracy = accuracy(\n",
    "                                    preds=test_predictions, refs=test_references\n",
    "                                )\n",
    "\n",
    "                                # save preds on valid_eqs\n",
    "                                predict_valid_eqs(model, f\"pred_{unique_name}\")\n",
    "\n",
    "                                print(\n",
    "                                    f\"\\tValid BLEU: {val_bleu:7.3f} | Valid Accuracy: {val_accuracy:7.3f}\"\n",
    "                                )\n",
    "                                update_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Hugging Face)",
   "language": "python",
   "name": "python_hf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
